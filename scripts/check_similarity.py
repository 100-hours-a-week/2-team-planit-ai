"""
ë²¡í„° DBì˜ ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ ìž…ë ¥ í…ìŠ¤íŠ¸ì™€ì˜ ìœ ì‚¬ë„ë¥¼ í™•ì¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

collection.get()ìœ¼ë¡œ ì „ì²´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ ë’¤ ì§ì ‘ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬
HNSW ê·¼ì‚¬ ê²€ìƒ‰ì— ì˜í•œ ëˆ„ë½ ì—†ì´ ì •í™•í•œ ì „ì²´ ë¹„êµë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/check_similarity.py "ìž…ë ¥ í…ìŠ¤íŠ¸"
    python scripts/check_similarity.py "ìž…ë ¥ í…ìŠ¤íŠ¸" --city "ì˜¤ì‚¬ì¹´"
    python scripts/check_similarity.py "ìž…ë ¥ í…ìŠ¤íŠ¸" --top 20
    python scripts/check_similarity.py "ìž…ë ¥ í…ìŠ¤íŠ¸" --metric euclidean
"""
import asyncio
import argparse
import sys
import os
import math
from typing import Callable, List, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import chromadb
from chromadb.config import Settings

from app.core.Agents.Poi.VectorDB.VectorSearchAgent import (
    VectorSearchAgent,
    DEFAULT_PERSIST_DIR,
)
from app.core.Agents.Poi.VectorDB.EmbeddingPipeline.EmbeddingPipeline import EmbeddingPipeline


# ============================================================
# ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜ (êµì²´ ê°€ëŠ¥)
# ìž…ë ¥: (vec_a, vec_b) -> float (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
# ============================================================

def cosine_similarity(a: List[float], b: List[float]) -> float:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ChromaDB ê¸°ë³¸ ë©”íŠ¸ë¦­ê³¼ ë™ì¼)"""
    dot = sum(x * y for x, y in zip(a, b))
    norm_a = math.sqrt(sum(x * x for x in a))
    norm_b = math.sqrt(sum(x * x for x in b))
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return dot / (norm_a * norm_b)


def dot_product_similarity(a: List[float], b: List[float]) -> float:
    """ë‚´ì (dot product) ìœ ì‚¬ë„"""
    return sum(x * y for x, y in zip(a, b))


def euclidean_similarity(a: List[float], b: List[float]) -> float:
    """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„ (ê±°ë¦¬ë¥¼ 0~1 ì ìˆ˜ë¡œ ë³€í™˜)"""
    dist = math.sqrt(sum((x - y) ** 2 for x, y in zip(a, b)))
    return 1.0 / (1.0 + dist)


# ë©”íŠ¸ë¦­ ì´ë¦„ â†’ í•¨ìˆ˜ ë§¤í•‘
SIMILARITY_METRICS: dict[str, Callable] = {
    "cosine": cosine_similarity,
    "dot": dot_product_similarity,
    "euclidean": euclidean_similarity,
}


async def check_similarity(
    query_text: str,
    city_filter: str | None = None,
    top_k: int | None = None,
    metric_name: str = "cosine",
):
    """ë²¡í„° DB ì „ì²´ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ì§ì ‘ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ì¶œë ¥"""

    similarity_fn = SIMILARITY_METRICS.get(metric_name)
    if similarity_fn is None:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë©”íŠ¸ë¦­: {metric_name}")
        print(f"   ì‚¬ìš© ê°€ëŠ¥: {', '.join(SIMILARITY_METRICS.keys())}")
        return

    # 1. ìž„ë² ë”© íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” & ì¿¼ë¦¬ ìž„ë² ë”© ìƒì„±
    embedding_pipeline = EmbeddingPipeline()
    query_embedding = await embedding_pipeline.embed_query(query_text)

    # 2. ChromaDBì—ì„œ ì „ì²´ ë°ì´í„° ì§ì ‘ ê°€ì ¸ì˜¤ê¸° (HNSW ìš°íšŒ)
    client = chromadb.PersistentClient(
        path=DEFAULT_PERSIST_DIR,
        settings=Settings(anonymized_telemetry=False),
    )
    collection = client.get_collection("poi_embeddings")
    total_count = collection.count()

    if total_count == 0:
        print("âš ï¸  ë²¡í„° DBì— ì €ìž¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì „ì²´ ë°ì´í„° ì¡°íšŒ (ìž„ë² ë”© í¬í•¨)
    data = collection.get(include=["embeddings", "metadatas", "documents"])

    print(f"ðŸ“¦ ë²¡í„° DB ì´ ë°ì´í„° ìˆ˜: {total_count}ê°œ")
    print(f"ðŸ” ê²€ìƒ‰ ì¿¼ë¦¬: \"{query_text}\"")
    print(f"ðŸ“ ìœ ì‚¬ë„ ë©”íŠ¸ë¦­: {metric_name}")
    if city_filter:
        print(f"ðŸ™ï¸  ë„ì‹œ í•„í„°: {city_filter}")
    print()

    # 3. ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ìœ ì‚¬ë„ ì§ì ‘ ê³„ì‚°
    scored_items: List[Tuple[float, int]] = []  # (score, index)

    for i, doc_id in enumerate(data["ids"]):
        metadata = data["metadatas"][i]
        embedding = data["embeddings"][i]

        # ë„ì‹œ í•„í„° ì ìš©
        if city_filter and metadata.get("city", "") != city_filter:
            continue

        if embedding is None:
            continue

        score = similarity_fn(query_embedding, embedding)
        scored_items.append((score, i))

    # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
    scored_items.sort(key=lambda x: x[0], reverse=True)

    # top_k ì ìš©
    if top_k:
        scored_items = scored_items[:top_k]

    if not scored_items:
        print("âš ï¸  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 4. ê²°ê³¼ ì¶œë ¥
    separator = "=" * 100
    print(separator)
    print(f"{'ìˆœìœ„':>4}  {'ìœ ì‚¬ë„':>8}  {'ì¹´í…Œê³ ë¦¬':<12}  {'ì´ë¦„':<30}  {'ë„ì‹œ':<10}  {'ì„¤ëª…'}")
    print(separator)

    for rank, (score, idx) in enumerate(scored_items, 1):
        metadata = data["metadatas"][idx]
        name = (metadata.get("name", "(ì´ë¦„ ì—†ìŒ)") or "(ì´ë¦„ ì—†ìŒ)")[:28]
        category = (metadata.get("category", "-") or "-")[:10]
        city = (metadata.get("city", "-") or "-")[:8]
        desc_raw = metadata.get("description", "-") or "-"
        desc = (desc_raw[:40] + "...") if len(desc_raw) > 40 else desc_raw

        if score >= 0.7:
            indicator = "ðŸŸ¢"
        elif score >= 0.5:
            indicator = "ðŸŸ¡"
        elif score >= 0.3:
            indicator = "ðŸŸ "
        else:
            indicator = "ðŸ”´"

        print(f"{rank:>4}  {indicator} {score:>6.4f}  {category:<12}  {name:<30}  {city:<10}  {desc}")

    print(separator)

    # 5. í†µê³„ ìš”ì•½
    scores = [s for s, _ in scored_items]
    avg_score = sum(scores) / len(scores) if scores else 0
    high_count = sum(1 for s in scores if s >= 0.7)
    mid_count = sum(1 for s in scores if 0.5 <= s < 0.7)
    low_count = sum(1 for s in scores if s < 0.5)

    filtered_total = len(scored_items) if not top_k else f"{len(scored_items)} (ì „ì²´ ì¤‘ top {top_k})"
    print(f"\nðŸ“Š ìš”ì•½ ({filtered_total} / DB ì „ì²´ {total_count}ê°œ)")
    print(f"   í‰ê·  ìœ ì‚¬ë„: {avg_score:.4f}")
    print(f"   ðŸŸ¢ ë†’ìŒ (â‰¥0.7): {high_count}ê°œ")
    print(f"   ðŸŸ¡ ë³´í†µ (0.5~0.7): {mid_count}ê°œ")
    print(f"   ðŸ”´ ë‚®ìŒ (<0.5): {low_count}ê°œ")


def main():
    parser = argparse.ArgumentParser(description="ë²¡í„° DB ìœ ì‚¬ë„ ê²€ìƒ‰ ë„êµ¬")
    parser.add_argument("query", type=str, help="ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìž…ë ¥ í…ìŠ¤íŠ¸")
    parser.add_argument("--city", type=str, default=None, help="ë„ì‹œ í•„í„° (ì˜ˆ: ì˜¤ì‚¬ì¹´)")
    parser.add_argument("--top", type=int, default=None, help="ìƒìœ„ Nê°œ ê²°ê³¼ ì¶œë ¥ (ê¸°ë³¸: ì „ì²´)")
    parser.add_argument(
        "--metric",
        type=str,
        default="cosine",
        choices=list(SIMILARITY_METRICS.keys()),
        help="ìœ ì‚¬ë„ ê³„ì‚° ë°©ì‹ (ê¸°ë³¸: cosine)",
    )

    args = parser.parse_args()
    asyncio.run(check_similarity(args.query, args.city, args.top, args.metric))


if __name__ == "__main__":
    main()

# LLMClient

## ğŸ“ ê°œìš”

LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸) ì„œë²„ì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” **í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ**ì…ë‹ˆë‹¤. ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤ë¥¼ í†µí•´ ê³µí†µ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•˜ê³ , vLLM ì„œë²„ ë° OpenAI APIë¥¼ ì§€ì›í•˜ëŠ” ë‘ ê°€ì§€ êµ¬í˜„ì²´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ëŠ” `httpx` ê¸°ë°˜ ë¹„ë™ê¸° í†µì‹ ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

---

## ğŸ“„ íŒŒì¼

### `BaseLlmClient.py`

LLM í´ë¼ì´ì–¸íŠ¸ì˜ **ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤**ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

#### ğŸ—ï¸ í´ë˜ìŠ¤: `BaseLLMClient(ABC)`

**ì„¤ëª…**: ëª¨ë“  LLM í´ë¼ì´ì–¸íŠ¸ê°€ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ê³µí†µ ì¸í„°í˜ì´ìŠ¤ì™€ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë¥¼ ì œê³µí•˜ëŠ” ì¶”ìƒ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

##### ğŸ“Œ í•„ë“œ (Attributes)

| í•„ë“œëª… | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|--------|------|--------|------|
| `base_url` | `str` | - | LLM ì„œë²„ ê¸°ë³¸ URL |
| `timeout` | `int` | `settings.llm_client_timeout` | ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ) |
| `max_retries` | `int` | `settings.llm_client_max_retries` | ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ |
| `max_tokens` | `int` | `settings.llm_client_max_tokens` | ìµœëŒ€ í† í° ìˆ˜ |
| `temperature` | `float` | `settings.llm_client_temperature` | ìƒì„± ì˜¨ë„ |
| `top_p` | `float` | `settings.llm_client_top_p` | Top-p ìƒ˜í”Œë§ ê°’ |

##### ğŸ”§ ë©”ì„œë“œ (Methods)

**`call_llm(prompt: ChatMessage) -> str`** *(ì¶”ìƒ, ë¹„ë™ê¸°)*

- **ì„¤ëª…**: ë¹„ìŠ¤íŠ¸ë¦¬ë° LLM í˜¸ì¶œ. ì „ì²´ ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

---

**`call_llm_stream(prompt: ChatMessage) -> AsyncIterator[str]`** *(ì¶”ìƒ, ë¹„ë™ê¸°)*

- **ì„¤ëª…**: ìŠ¤íŠ¸ë¦¬ë° LLM í˜¸ì¶œ. SSE ë°©ì‹ìœ¼ë¡œ ì‘ë‹µì„ ì²­í¬ ë‹¨ìœ„ë¡œ yieldí•©ë‹ˆë‹¤.

---

**`call_llm_structured(prompt: ChatMessage, model: Type[T]) -> T`** *(ì¶”ìƒ, ë¹„ë™ê¸°)*

- **ì„¤ëª…**: êµ¬ì¡°í™”ëœ ì¶œë ¥ LLM í˜¸ì¶œ. Pydantic ëª¨ë¸ íƒ€ì…ì„ ë°›ì•„ JSON Schema ê¸°ë°˜ìœ¼ë¡œ íŒŒì‹±ëœ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

---

**`messageDataToDict(messageData: MessageData) -> Dict[str, str]`**

- **ì„¤ëª…**: `MessageData` ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

---

**`dictToMessageData(dict: Dict[str, str]) -> MessageData`**

- **ì„¤ëª…**: ë”•ì…”ë„ˆë¦¬ë¥¼ `MessageData` ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

---

**`chatMessageToDictList(chatMessage: ChatMessage) -> List[Dict[str, str]]`**

- **ì„¤ëª…**: `ChatMessage`ì˜ ë©”ì‹œì§€ ëª©ë¡ì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. API ìš”ì²­ ì‹œ ì‚¬ìš©ë©ë‹ˆë‹¤.

---

**`dictListToChatMessage(messages: List[Dict[str, str]]) -> ChatMessage`**

- **ì„¤ëª…**: ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ `ChatMessage` ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

---

**`stripJsonCodeFence(content: str) -> str`**

- **ì„¤ëª…**: LLM ì‘ë‹µì—ì„œ JSON ì½”ë“œ ë¸”ë¡ (```` ```json ... ``` ````)ì„ ì œê±°í•˜ì—¬ ìˆœìˆ˜ JSON ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

---

### `OpenAiApiClient.py`

OpenAI API í˜¸í™˜ ì„œë²„ë¥¼ ìœ„í•œ **êµ¬í˜„ í´ë¼ì´ì–¸íŠ¸**ì…ë‹ˆë‹¤.

#### ğŸ—ï¸ í´ë˜ìŠ¤: `OpenAiApiClient(BaseLLMClient)`

**ì„¤ëª…**: OpenAI APIë¥¼ `httpx` ê¸°ë°˜ ë¹„ë™ê¸° HTTPë¡œ í˜¸ì¶œí•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ì…ë‹ˆë‹¤. Bearer í† í° ì¸ì¦ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

##### ğŸ“Œ í•„ë“œ (Attributes)

| í•„ë“œëª… | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|--------|------|--------|------|
| `api_key` | `Optional[str]` | `settings.openai_api_key` | OpenAI API í‚¤ |
| `model` | `Optional[str]` | `settings.openai_model` | ì‚¬ìš©í•  ëª¨ë¸ëª… |

*(ìƒì† í•„ë“œ: `base_url`, `timeout`, `max_retries`, `max_tokens`, `temperature`, `top_p`)*

##### ğŸ”§ ë©”ì„œë“œ (Methods)

**`call_llm_stream(prompt: ChatMessage) -> AsyncIterator[str]`** *(ë¹„ë™ê¸°)*

- **ì„¤ëª…**: OpenAI SSE ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œ. `data: {json}` í˜•ì‹ì˜ ë¼ì¸ì„ ì½ì–´ contentë¥¼ yieldí•©ë‹ˆë‹¤.
- **ì—”ë“œí¬ì¸íŠ¸**: `{base_url}/chat/completions`
- **ì¬ì‹œë„**: ì§€ìˆ˜ ë°±ì˜¤í”„ (`2^attempt`ì´ˆ)

---

**`call_llm(prompt: ChatMessage) -> str`** *(ë¹„ë™ê¸°)*

- **ì„¤ëª…**: OpenAI ë¹„ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œ. ì „ì²´ ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
- **ì¬ì‹œë„**: ì§€ìˆ˜ ë°±ì˜¤í”„

---

**`call_llm_structured(prompt: ChatMessage, model: Type[T]) -> T`** *(ë¹„ë™ê¸°)*

- **ì„¤ëª…**: JSON Schema ê¸°ë°˜ êµ¬ì¡°í™”ëœ ì¶œë ¥ í˜¸ì¶œ. `response_format`ì— `json_schema`ë¥¼ ì„¤ì •í•˜ì—¬ Pydantic ëª¨ë¸ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
- **íŠ¹ì´ì‚¬í•­**: `_enforce_no_additional_props()`ë¡œ ìŠ¤í‚¤ë§ˆì— `additionalProperties: false`ë¥¼ ê°•ì œí•©ë‹ˆë‹¤.

---

#### ğŸ”§ ëª¨ë“ˆ ë ˆë²¨ í•¨ìˆ˜

**`_enforce_no_additional_props(schema: dict) -> dict`**

- **ì„¤ëª…**: JSON Schemaì˜ ëª¨ë“  object íƒ€ì…ì— `additionalProperties: false`ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤. OpenAI Strict Mode í˜¸í™˜ì„ ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.

---

### `VllmClient.py`

vLLM ì„œë²„ë¥¼ ìœ„í•œ **êµ¬í˜„ í´ë¼ì´ì–¸íŠ¸**ì…ë‹ˆë‹¤.

#### ğŸ—ï¸ í´ë˜ìŠ¤: `VllmClient(BaseLLMClient)`

**ì„¤ëª…**: vLLM ì„œë²„ë¥¼ `httpx` ê¸°ë°˜ ë¹„ë™ê¸° HTTPë¡œ í˜¸ì¶œí•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ì…ë‹ˆë‹¤. ì¸ì¦ ì—†ì´ ì§ì ‘ ì„œë²„ì— ì—°ê²°í•©ë‹ˆë‹¤.

##### ğŸ“Œ í•„ë“œ (Attributes)

| í•„ë“œëª… | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|--------|------|--------|------|
| `base_url` | `str` | `settings.vllm_base_url` | vLLM ì„œë²„ URL (trailing slash ì œê±°) |

*(ìƒì† í•„ë“œ: `timeout`, `max_retries`, `max_tokens`, `temperature`, `top_p`)*

##### ğŸ”§ ë©”ì„œë“œ (Methods)

**`call_llm_stream(prompt: ChatMessage) -> AsyncIterator[str]`** *(ë¹„ë™ê¸°)*

- **ì„¤ëª…**: vLLM SSE ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œ. ë¸íƒ€ ë°©ì‹ìœ¼ë¡œ contentë¥¼ yieldí•©ë‹ˆë‹¤.
- **ì—”ë“œí¬ì¸íŠ¸**: `{base_url}/v1/chat/completions`
- **ì¬ì‹œë„**: ì§€ìˆ˜ ë°±ì˜¤í”„, HTTP 503 ì‹œ ìë™ ì¬ì‹œë„
- **íŠ¹ì´ì‚¬í•­**: vLLMì˜ ëˆ„ì  ë¬¸ìì—´ ë°˜í™˜ ë°©ì‹ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ `content_len` ìŠ¬ë¼ì´ì‹± ì‚¬ìš©

---

**`call_llm(prompt: ChatMessage) -> str`** *(ë¹„ë™ê¸°)*

- **ì„¤ëª…**: vLLM ë¹„ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œ. ì „ì²´ ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
- **ì¬ì‹œë„**: ì§€ìˆ˜ ë°±ì˜¤í”„, HTTP 503 ì‹œ ìë™ ì¬ì‹œë„

---

**`call_llm_structured(prompt: ChatMessage, model: Type[T]) -> T`** *(ë¹„ë™ê¸°)*

- **ì„¤ëª…**: vLLM Guided Decodingì„ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ í˜¸ì¶œ. `response_format`ì— `json_schema`ë¥¼ ì„¤ì •í•˜ì—¬ Pydantic ëª¨ë¸ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
- **ì¬ì‹œë„**: ì§€ìˆ˜ ë°±ì˜¤í”„, HTTP 503 ì‹œ ìë™ ì¬ì‹œë„

---

### `LangchainClient.py`

LangChain `ChatOpenAI` ê¸°ë°˜ **êµ¬ì¡°í™” ì¶œë ¥ ì „ìš© í´ë¼ì´ì–¸íŠ¸**ì…ë‹ˆë‹¤. `BaseLLMClient` ê³„ì¸µê³¼ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.

#### ğŸ—ï¸ í´ë˜ìŠ¤: `LangchainClient`

**ì„¤ëª…**: LangChainì˜ `with_structured_output`ì„ ì‚¬ìš©í•˜ì—¬ Pydantic ëª¨ë¸ë¡œ ì§ì ‘ íŒŒì‹±í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ì…ë‹ˆë‹¤. vLLM OpenAI í˜¸í™˜ APIë¥¼ ë°±ì—”ë“œë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

##### ğŸ“Œ í•„ë“œ (Attributes)

| í•„ë“œëª… | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|--------|------|--------|------|
| `base_url` | `str` | `settings.vllm_base_url` | vLLM OpenAI í˜¸í™˜ API ë² ì´ìŠ¤ URL |
| `model` | `str` | `settings.vllm_model` | vLLM ëª¨ë¸ ì´ë¦„ |
| `api_key` | `str` | `"EMPTY"` | API í‚¤ (vLLMì€ "EMPTY" ì‚¬ìš©) |
| `temperature` | `float \| None` | `settings.llm_client_temperature` | ìƒì„± ì˜¨ë„ |
| `max_tokens` | `int` | `settings.llm_client_max_tokens` | ìµœëŒ€ í† í° ìˆ˜ |

##### ğŸ”§ ë©”ì„œë“œ (Methods)

**`call_structured(prompt: ChatMessage, model: Type[T]) -> T`** *(ë¹„ë™ê¸°)*

- **ì„¤ëª…**: LangChainì˜ `with_structured_output`ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ Pydantic ëª¨ë¸ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
- **íŠ¹ì´ì‚¬í•­**: `BaseLLMClient`ë¥¼ ìƒì†í•˜ì§€ ì•Šê³  ë…ë¦½ì ìœ¼ë¡œ ë™ì‘. LangChainì˜ structured output ê¸°ëŠ¥ì— ì˜ì¡´í•©ë‹ˆë‹¤.

---

**`_convert_messages(prompt: ChatMessage) -> list`** *(ì •ì  ë©”ì„œë“œ)*

- **ì„¤ëª…**: `ChatMessage`ë¥¼ LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸(`SystemMessage`, `HumanMessage`)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

---

## ğŸ”— ì˜ì¡´ì„±

- `app.core.config`: `settings` ê°ì²´ (í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì •)
- `app.core.models.LlmClientDataclass.ChatMessageDataclass`: `ChatMessage`, `MessageData` ë°ì´í„° ëª¨ë¸
- `httpx`: ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸
- `langchain_openai`: `ChatOpenAI` (LangchainClient)
- `langchain_core`: `SystemMessage`, `HumanMessage` (LangchainClient)
- `abc`: ì¶”ìƒ í´ë˜ìŠ¤ ì •ì˜

## ğŸ”— íŒŒì¼ ê°„ ê´€ê³„

```
BaseLLMClient (ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤)
â”œâ”€â”€ OpenAiApiClient  - OpenAI API í˜¸í™˜ ì„œë²„ìš©
â””â”€â”€ VllmClient       - vLLM ì„œë²„ìš©

LangchainClient (ë…ë¦½ í´ë˜ìŠ¤, vLLM ë°±ì—”ë“œ)
â””â”€â”€ LangChain ChatOpenAI ê¸°ë°˜ êµ¬ì¡°í™” ì¶œë ¥ ì „ìš©
```

- `BaseLlmClient.py`ëŠ” ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤ì™€ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
- `OpenAiApiClient.py`ì™€ `VllmClient.py`ëŠ” ê°ê° `BaseLLMClient`ë¥¼ ìƒì†í•˜ì—¬ êµ¬í˜„í•©ë‹ˆë‹¤.
- ë‘ êµ¬í˜„ì²´ ëª¨ë‘ ë™ì¼í•œ 3ê°œì˜ ì¶”ìƒ ë©”ì„œë“œ(`call_llm`, `call_llm_stream`, `call_llm_structured`)ë¥¼ êµ¬í˜„í•˜ë©°, ê³µí†µ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë¥¼ ìƒì†ë°›ìŠµë‹ˆë‹¤.
- `OpenAiApiClient`ëŠ” Bearer í† í° ì¸ì¦ì„ ì‚¬ìš©í•˜ê³ , `VllmClient`ëŠ” ì¸ì¦ ì—†ì´ ì§ì ‘ ì—°ê²°í•©ë‹ˆë‹¤.
- `LangchainClient`ëŠ” `BaseLLMClient` ê³„ì¸µê³¼ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘í•˜ë©°, vLLM ì„œë²„ë¥¼ LangChain `ChatOpenAI`ë¥¼ í†µí•´ ì‚¬ìš©í•©ë‹ˆë‹¤. êµ¬ì¡°í™” ì¶œë ¥(`with_structured_output`)ì´ í•„ìš”í•œ ê²½ìš°ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
